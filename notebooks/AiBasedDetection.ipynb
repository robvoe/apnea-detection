{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ..\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Dict, Iterable, List, Tuple\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from ai_based.data_handling.ai_datasets import AiDataset\n",
    "from ai_based.data_handling.training_batch import TrainingBatch\n",
    "from ai_based.networks import MLP, Cnn1D\n",
    "from ai_based.utilities.evaluators import ConfusionMatrixEvaluator\n",
    "from util.paths import RESULTS_PATH_AI, TRAIN_TEST_SPLIT_YAML, DATA_PATH\n",
    "from util.train_test_split import read_train_test_split_yaml\n",
    "from ai_based.utilities.evaluators import BaseEvaluator\n",
    "from util.datasets import GroundTruthClass, RespiratoryEvent, RespiratoryEventType, \\\n",
    "    RESPIRATORY_EVENT_TYPE__GROUND_TRUTH_CLASS, SlidingWindowDataset\n",
    "from util.mathutil import cluster_1d, IntRange\n",
    "from ai_based.utilities.inference import retrieve_respiratory_events\n",
    "from util.event_based_metrics import get_overlaps, get_n_detected_annotations, OverlapsBasedConfusionMatrix\n",
    "\n",
    "# Some preparations to pretty-print tensors & ndarrays\n",
    "np.set_printoptions(edgeitems=10)\n",
    "np.core.arrayprint._line_width = 400\n",
    "torch.set_printoptions(linewidth=400)\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "\n",
    "n_cpu_cores = len(os.sched_getaffinity(0))\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load model, training config, training logs, etc.\n",
    "- Training runs are organized as so-called **experiments**.\n",
    "- An experiment may be run multiple times in different model & hyper-parameter configurations. Each run is called a **combination**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EXPERIMENT_DIR = RESULTS_PATH_AI / \"cnn-5-gt_point-bs128-peakified_signals-low_wd-train_noise\"\n",
    "COMBINATION_DIR = EXPERIMENT_DIR / \"combination_0\"\n",
    "REPETITION_DIR = COMBINATION_DIR / \"repetition_0\"\n",
    "\n",
    "assert RESULTS_PATH_AI.is_dir() and RESULTS_PATH_AI.exists()\n",
    "assert EXPERIMENT_DIR.is_dir() and EXPERIMENT_DIR.exists()\n",
    "assert COMBINATION_DIR.is_dir() and COMBINATION_DIR.exists()\n",
    "assert REPETITION_DIR.is_dir() and REPETITION_DIR.exists()\n",
    "\n",
    "if (REPETITION_DIR / \"log.pt\").exists():\n",
    "    log = torch.load(REPETITION_DIR / \"log.pt\", map_location=torch.device(\"cpu\"))\n",
    "else:\n",
    "    log = None\n",
    "    print(\"No training logs available\")\n",
    "\n",
    "if (REPETITION_DIR / \"eval.pt\").exists():\n",
    "    final_validation_eval_results = torch.load(REPETITION_DIR / \"eval.pt\", map_location=torch.device(\"cpu\"))\n",
    "else:\n",
    "    final_validation_eval_results = None\n",
    "    print(\"No final eval results available\")\n",
    "\n",
    "config = torch.load(EXPERIMENT_DIR / \"config.pt\", map_location=torch.device(\"cpu\"))\n",
    "hyperparams = torch.load(COMBINATION_DIR / \"params.pt\", map_location=torch.device(\"cpu\"))\n",
    "if (REPETITION_DIR / \"weights.pt\").exists():\n",
    "    weights = torch.load(REPETITION_DIR / \"weights.pt\", map_location=torch.device(\"cpu\"))\n",
    "elif (REPETITION_DIR / \"checkpoint_best_weights.pt\").exists():\n",
    "    weights = torch.load(REPETITION_DIR / \"checkpoint_best_weights.pt\", map_location=torch.device(\"cpu\"))\n",
    "else:\n",
    "    raise RuntimeError(\"No weights file found\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print()\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = hyperparams[\"model\"](hyperparams[\"model_config\"])\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot parameters that were logged during training\n",
    "These are, amongst others:\n",
    "- Training loss\n",
    "- Training metrics (precision, recall, f1-score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(24, 36))\n",
    "\n",
    "axes[0, 0].set_title(\"Loss\")\n",
    "axes[0, 0].plot(log[\"training\"][\"loss\"])\n",
    "\n",
    "axes[0, 1].set_title(\"Weighted mean IoU\")\n",
    "# axes[0, 1].plot(training_miou, label=\"training\")\n",
    "# axes[0, 1].plot(validation_miou, label=\"validation\")\n",
    "axes[0, 1].legend()\n",
    "\n",
    "axes[1, 0].set_title(\"Detection Recall\")\n",
    "# axes[1, 0].plot(log[\"training\"][\"detection_recall\"], label=\"training\")\n",
    "# axes[1, 0].plot(log[\"validation\"][\"detection_recall\"], label=\"validation\")\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].set_title(\"Placement Accuracy\")\n",
    "# axes[1, 1].plot(log[\"training\"][\"placement_accuracy\"], label=\"training\")\n",
    "# axes[1, 1].plot(log[\"validation\"][\"placement_accuracy\"], label=\"validation\")\n",
    "axes[1, 1].legend()\n",
    "\n",
    "axes[2, 0].set_title(\"Object Height Accuracy\")\n",
    "# axes[2, 0].plot(log[\"training\"][\"height_classification_accuracy\"], label=\"training\")\n",
    "# axes[2, 0].plot(log[\"validation\"][\"height_classification_accuracy\"], label=\"validation\")\n",
    "axes[2, 0].legend()\n",
    "\n",
    "axes[2, 1].set_title(\"Pixel Height Accuracy\")\n",
    "# axes[2, 1].plot(log[\"training\"][\"accuracy\"], label=\"training\")\n",
    "# axes[2, 1].plot(log[\"validation\"][\"accuracy\"], label=\"validation\")\n",
    "axes[2, 1].legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training-specific metrics\n",
    "The metrics of this sub-section are train batch based and only used during training to\n",
    "compare different states of a model (e.g. to compare different epochs).\n",
    "\n",
    "In order to compare detectors of any kind (i.e. rule-based/AI-based), it is strongly recommended\n",
    "to rely on EventBasedMetrics instead. These EventBasedMetrics will be used throughout\n",
    "the next examples down below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_folder = DATA_PATH / \"training\" / \"tr03-0005\"\n",
    "\n",
    "ai_dataset_config = copy.deepcopy(hyperparams[\"test_dataset_config\"])\n",
    "ai_dataset_config.dataset_folders = [dataset_folder]\n",
    "ai_dataset_config.noise_mean_std = None\n",
    "ai_dataset = AiDataset(config=ai_dataset_config)\n",
    "data_loader = torch.utils.data.DataLoader(ai_dataset, batch_size=batch_size, shuffle=False, collate_fn=TrainingBatch.from_iterable, num_workers=n_cpu_cores-1)\n",
    "\n",
    "# Iterate over the dataset and gather performance information\n",
    "overall_evaluator = ConfusionMatrixEvaluator.empty()\n",
    "for batch in tqdm(data_loader):\n",
    "    batch.to_device(model.device)\n",
    "    net_input = torch.autograd.Variable(batch.input_data)\n",
    "    net_output = model(net_input)\n",
    "    batch_evaluator = ConfusionMatrixEvaluator(model_output_batch=net_output, ground_truth_batch=batch.ground_truth)\n",
    "    overall_evaluator += batch_evaluator\n",
    "\n",
    "overall_evaluator.print_exhausting_metrics_results(include_short_summary=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AI detection run over a single dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's load a single dataset and output a few statistics on it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_folder = DATA_PATH / \"training\" / \"tr03-0005\"\n",
    "\n",
    "ai_dataset_config = copy.deepcopy(hyperparams[\"test_dataset_config\"])\n",
    "ai_dataset_config.dataset_folders = [dataset_folder]\n",
    "ai_dataset_config.noise_mean_std = None\n",
    "ai_dataset = AiDataset(config=ai_dataset_config)\n",
    "print(f\"#Sliding window positions: {len(ai_dataset)}\")\n",
    "\n",
    "assert len(ai_dataset._sliding_window_datasets) == 1, \\\n",
    "    \"The given AiDataset contains more than one SlidingWindowDatasets. This example's intention is to show predictions on a single dataset sample.\"\n",
    "\n",
    "# For plotting later on, we need to reload our SlidingWindowDataset. That's because during preprocessing, its signal data was modified by AiDataset\n",
    "sliding_window_dataset = ai_dataset._sliding_window_datasets[0]\n",
    "sliding_window_dataset = SlidingWindowDataset(config=sliding_window_dataset.config, dataset_folder=sliding_window_dataset.dataset_folder, allow_caching=True)\n",
    "\n",
    "print(f\"#Physionet dataset samples: {len(sliding_window_dataset.signals)}\")\n",
    "print(f\"Timeframe of sliding window positions: {sliding_window_dataset.valid_center_points[-1] - sliding_window_dataset.valid_center_points[0]}\")\n",
    "print(f\"Respiratory events list present: {sliding_window_dataset.respiratory_events is not None}\")\n",
    "\n",
    "if sliding_window_dataset.respiratory_events is None:\n",
    "    print()\n",
    "    print()\n",
    "    print(\"The given dataset does not provide annotated respiratory events. For the following example, we need those annotations!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Outputting some infos on the annotated respiratory events"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annotated_respiratory_events = sliding_window_dataset.respiratory_events\n",
    "\n",
    "respiratory_event_type_counter = Counter([e.event_type for e in annotated_respiratory_events])\n",
    "print(\"Respiratory event types as per annotations:\")\n",
    "print(\" - \" + \"\\n - \".join(f\"{klass.name}: {cnt}\" for klass, cnt in respiratory_event_type_counter.items()))\n",
    "print()\n",
    "print(f\"{len(annotated_respiratory_events)} annotated respiratory events:\")\n",
    "print(\" - \" + \"\\n - \".join([f\"#{i}: {evt}\" for i, evt in enumerate(annotated_respiratory_events)]))\n",
    "\n",
    "# Enrich whole sliding window dataset by \"is awake\" row\n",
    "awake_series = sliding_window_dataset.awake_series\n",
    "sliding_window_dataset.signals[awake_series.name] = awake_series\n",
    "del awake_series\n",
    "\n",
    "# Enrich whole sliding window dataset by an events outline\n",
    "annotated_events_outline_mat = np.zeros(shape=(len(sliding_window_dataset.signals),))\n",
    "for event in annotated_respiratory_events:\n",
    "    start_idx = sliding_window_dataset.signals.index.get_loc(event.start, method=\"nearest\")\n",
    "    end_idx = sliding_window_dataset.signals.index.get_loc(event.end, method=\"nearest\")\n",
    "    annotated_events_outline_mat[start_idx:end_idx] = 1\n",
    "annotated_events_outline_series = pd.Series(data=annotated_events_outline_mat, index=sliding_window_dataset.signals.index)\n",
    "sliding_window_dataset.signals[\"Annotated respiratory events\"] = annotated_events_outline_series\n",
    "\n",
    "del annotated_events_outline_series, annotated_events_outline_mat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform the detection. Also generate an outline for the detected events,\n",
    "which is nice for plotting purposes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "events_dict = retrieve_respiratory_events(model=model, ai_dataset=ai_dataset, batch_size=batch_size, progress_fn=tqdm, min_cluster_length_s=7)\n",
    "detected_respiratory_events = events_dict[sliding_window_dataset.dataset_name]\n",
    "\n",
    "detected_hypopnea_events_ = [d_ for d_ in detected_respiratory_events if d_.event_type == RespiratoryEventType.Hypopnea]\n",
    "detected_apnea_events_ = [d_ for d_ in detected_respiratory_events if d_.event_type != RespiratoryEventType.Hypopnea]\n",
    "\n",
    "print()\n",
    "print(f\"Detected {len(detected_respiratory_events)} respiratory events\")\n",
    "print(f\" ..of which are {len(detected_hypopnea_events_)} hypopneas\")\n",
    "\n",
    "# Enrich the sliding window dataset by an events outline\n",
    "detected_events_outline_mat = np.zeros(shape=(len(sliding_window_dataset.signals),))\n",
    "for event in detected_respiratory_events:\n",
    "    start_idx = sliding_window_dataset.signals.index.get_loc(event.start, method=\"nearest\")\n",
    "    end_idx = sliding_window_dataset.signals.index.get_loc(event.end, method=\"nearest\")\n",
    "    detected_events_outline_mat[start_idx:end_idx] = 1\n",
    "detected_events_outline_series = pd.Series(data=detected_events_outline_mat, index=sliding_window_dataset.signals.index)\n",
    "sliding_window_dataset.signals[\"Detected respiratory events\"] = detected_events_outline_series\n",
    "\n",
    "del detected_events_outline_series, detected_events_outline_mat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate and output some statistics on the detection performance. These are:\n",
    "- Overlaps of detected & annotated respiratory events\n",
    "- Confusion matrix based metrics\n",
    "- Confusion matrix plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get overlapping annotated/detected events & derive some statistics\n",
    "overlapping_events = get_overlaps(annotated_events=annotated_respiratory_events, detected_events=detected_respiratory_events)\n",
    "detected_but_not_annotated = [d_ for d_ in detected_respiratory_events if not any(a_.overlaps(d_) for a_ in annotated_respiratory_events)]\n",
    "annotated_but_not_detected = [a_ for a_ in annotated_respiratory_events if not any(d_.overlaps(a_) for d_ in detected_respiratory_events)]\n",
    "\n",
    "print(f\"Number of annotated events: {len(annotated_respiratory_events)}\")\n",
    "print(f\"Number of detected events: {len(detected_respiratory_events)}\")\n",
    "print()\n",
    "print(f\"Number of OVERLAPPING events: {len(overlapping_events)}\")\n",
    "print(f\"- Coverage of annotated respiratory events {len(overlapping_events)/len(annotated_respiratory_events)*100:.1f}%\")\n",
    "print(f\"- Detected events that also appear in annotations: {len(overlapping_events)/len(detected_respiratory_events)*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# Obtain confusion-matrix based metrics\n",
    "confusion_matrix = OverlapsBasedConfusionMatrix(annotated_events=annotated_respiratory_events, detected_events=detected_respiratory_events)\n",
    "macro_scores = confusion_matrix.get_macro_scores()\n",
    "print(\"Confusion-matrix based macro scores:\")\n",
    "print(f\" -> {macro_scores}\")\n",
    "\n",
    "confusion_matrix.plot(title=\"Confusion matrix for classification confidence over a single dataset\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following lines allow plotting annotated & detected respiratory events"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "event_num = 11\n",
    "# event = annotated_respiratory_events[event_num]\n",
    "event = detected_respiratory_events[event_num]\n",
    "# event = detected_but_not_annotated[event_num]\n",
    "# event = annotated_but_not_detected[event_num]\n",
    "# event = detected_hypopnea_events[event_num]\n",
    "\n",
    "# Let's determine a few values, then plot\n",
    "window_center_point = event.start + (event.end-event.start)/2\n",
    "window_start = window_center_point - sliding_window_dataset.config.time_window_size / 2\n",
    "window_end = window_center_point + sliding_window_dataset.config.time_window_size / 2\n",
    "\n",
    "annotated_in_window = [e for e in annotated_respiratory_events if e.end > window_start and e.start < window_end]\n",
    "detected_in_window = [e for e in detected_respiratory_events if e.end > window_start and e.start < window_end]\n",
    "print()\n",
    "print(\"Annotated respiratory events in window:\")\n",
    "print(\" - \" + \"\\n - \".join([f\"{e.event_type.name}: {(e.end-e.start).total_seconds():.1f}s\" for e in annotated_in_window]))\n",
    "print()\n",
    "print(\"Detected respiratory events in window:\")\n",
    "print(\" - \" + \"\\n - \".join([f\"{e.event_type.name}: {(e.end-e.start).total_seconds():.1f}s\" for e in detected_in_window]))\n",
    "\n",
    "window_data = sliding_window_dataset.get(center_point=window_center_point)\n",
    "_ = window_data.signals.plot(figsize=(25, 12), subplots=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detection run over a multiple datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run AI-based detector on a number of datasets."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use training dataset folders as per train-test-split\n",
    "data_folder = DATA_PATH / \"training\"\n",
    "train_test_folders = read_train_test_split_yaml(input_yaml=TRAIN_TEST_SPLIT_YAML, prefix_base_folder=data_folder)\n",
    "dataset_folders = train_test_folders.train\n",
    "del train_test_folders\n",
    "\n",
    "# Use a given, small set of dataset folders\n",
    "dataset_names = (\"tr03-0005\", \"tr03-0289\", \"tr03-0921\", \"tr04-1078\", \"tr07-0168\")\n",
    "dataset_folders = [DATA_PATH / \"training\" / name for name in dataset_names]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load our datasets\n",
    "ai_dataset_config = copy.deepcopy(hyperparams[\"test_dataset_config\"])\n",
    "ai_dataset_config.dataset_folders = dataset_folders\n",
    "ai_dataset_config.noise_mean_std = None\n",
    "ai_dataset = AiDataset(config=ai_dataset_config)\n",
    "\n",
    "assert all(ds.respiratory_events is not None for ds in ai_dataset._sliding_window_datasets),\\\n",
    "    \"At least one of the sub-datasets has no annotations.\"\n",
    "\n",
    "# Perform the detection run\n",
    "progress_fn = functools.partial(tqdm, desc=\"Detecting\")\n",
    "detected_events_dict = retrieve_respiratory_events(model=model, ai_dataset=ai_dataset, batch_size=batch_size, progress_fn=progress_fn)\n",
    "\n",
    "# Reload our SlidingWindowDatasets for later plotting purposes. That's necessary, because their signals were modified by AiDataset\n",
    "print()\n",
    "print(\"Reload SlidingWindowDatasets for plotting purposes.. \", end=\"\")\n",
    "sliding_window_datasets = []\n",
    "for ds in ai_dataset._sliding_window_datasets:\n",
    "    ds_reloaded = SlidingWindowDataset(config=ds.config, dataset_folder=ds.dataset_folder, allow_caching=True)\n",
    "    sliding_window_datasets += [ds_reloaded]\n",
    "print(\"Finished\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "detected_events_dict_flattened_ = [event for event_list in detected_events_dict.values() for event in event_list]\n",
    "detected_hypopnea_events_ = [d_ for d_ in detected_events_dict_flattened_ if d_.event_type == RespiratoryEventType.Hypopnea]\n",
    "detected_apnea_events_ = [d_ for d_ in detected_events_dict_flattened_ if d_.event_type != RespiratoryEventType.Hypopnea]\n",
    "\n",
    "print()\n",
    "print(f\"Detected {len(detected_events_dict_flattened_)} respiratory events in all {len(sliding_window_datasets)} datasets\")\n",
    "print(f\" ..of which are {len(detected_hypopnea_events_)} hypopneas\")\n",
    "del detected_events_dict_flattened_, detected_hypopnea_events_, detected_apnea_events_\n",
    "\n",
    "# Enrich the SlidingWindowDataset by event outlines\n",
    "for sliding_window_dataset in sliding_window_datasets:\n",
    "    detected_events_outline_mat = np.zeros(shape=(len(sliding_window_dataset.signals),))\n",
    "    for event in detected_events_dict[sliding_window_dataset.dataset_name]:\n",
    "        start_idx = sliding_window_dataset.signals.index.get_loc(event.start, method=\"nearest\")\n",
    "        end_idx = sliding_window_dataset.signals.index.get_loc(event.end, method=\"nearest\")\n",
    "        detected_events_outline_mat[start_idx:end_idx] = 1\n",
    "    detected_events_outline_series = pd.Series(data=detected_events_outline_mat, index=sliding_window_dataset.signals.index)\n",
    "    sliding_window_dataset.signals[\"Detected respiratory events\"] = detected_events_outline_series\n",
    "del detected_events_outline_series, detected_events_outline_mat\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run a few metrics on the freshly-detected respiratory events. Also, directly print out a few statistics on overlaps\n",
    "of annotated & detected respiratory events, which results in the __annotation recall__ score."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run metrics on our detections\n",
    "overall_confusion_matrix = OverlapsBasedConfusionMatrix.empty()\n",
    "n_annotated_events: int = 0\n",
    "n_detected_events: int = 0\n",
    "n_detected_annotations: int = 0\n",
    "for sliding_window_dataset in sliding_window_datasets:\n",
    "    detected_events = detected_events_dict[sliding_window_dataset.dataset_name]\n",
    "    n_detected_events += len(detected_events)\n",
    "    n_annotated_events += len(sliding_window_dataset.respiratory_events)\n",
    "\n",
    "    cm_ = OverlapsBasedConfusionMatrix(annotated_events=sliding_window_dataset.respiratory_events, detected_events=detected_events)\n",
    "    overall_confusion_matrix += cm_\n",
    "    o_ = get_n_detected_annotations(annotated_events=sliding_window_dataset.respiratory_events, detected_events=detected_events)\n",
    "    n_detected_annotations += o_\n",
    "\n",
    "print(f\"Number of annotated respiratory events: {n_annotated_events}\")\n",
    "print(f\"Number of detected respiratory events: {n_detected_events}\")\n",
    "print()\n",
    "print(f\"Number of detected annotations (overlaps): {n_detected_annotations} out of {n_annotated_events}\")\n",
    "print(f\" -> Annotation recall: {n_detected_annotations/n_annotated_events:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the confusion matrix and the derived scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "macro_scores = overall_confusion_matrix.get_macro_scores()\n",
    "print(\"Confusion-matrix based macro scores:\")\n",
    "print(f\" -> {macro_scores}\")\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "overall_confusion_matrix.plot(title=f\"Confusion matrix for classification confidence over {len(dataset_folders)} datasets\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}